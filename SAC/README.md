In **SAC_discreet.ipynb** notebook, we implement and experiment with the Soft Actor-Critic (SAC) algorithm for discrete action spaces using PyTorch on the classic CartPole environment.
It includes environment setup, neural network definitions, training loops, replay buffer management, and evaluation routines, making it a complete, reproducible reference for discrete SAC in reinforcement learning tasks. 

![](https://github.com/ahmad-karami/Reinforcement-Learning/blob/main/SAC/CartPole.gif)
